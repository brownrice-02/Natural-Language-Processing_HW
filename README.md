# Natural Language Processing Homework
NLP 2022 Spring

## Lab 1: Data Preprocessing and N-Gram Model
### Part 1: Data Preprocessing 
- Display the top-10 common words and their counts before and after preprocessing.

### Part 2: N-Gram Model and POS Tagging 
- Build a 2-gram model with the processed dataset.
- Show the top-5 probable next words and their probabilities after the initial token â€˜<s>â€™.
- Generate a sentence with the 2-gram model and find the corresponding POS taggings.

### Part 3: Evaluation

## Lab 2: Clustering Techniques
### Part 1: K-Means Clustering
- **Problem 1-1:** Determine the optimal value of k.
- **Problem 1-2:** Discuss the observations and findings.

### Part 2: Agglomerative Clustering
- **Problem 2-1:** Implement three hierarchical clustering methods.
- **Problem 2-2:** Discuss the observations and findings.

## Lab 3: Parsing and HMM Implementation
### Parsing
- Render dependency trees.
- Implement constituency parsing.
- Perform dependency parsing using Spacy.

### HMM Implementation
- Solve the POS tagging task with Hidden Markov Models (HMM) and Viterbi algorithm.

## Lab 4: Text Classification with BERT
- Utilize BERT (Bidirectional Encoder Representations from Transformers) for text classification tasks.

Feel free to explore each lab's directory for detailed implementations and explanations of the respective tasks. If you have any questions or suggestions, please don't hesitate to reach out.

Happy coding! ðŸ˜Š
