# Natural Language Processing Homework
NLP 2022 Spring

## Lab 1: Data Preprocessing and N-Gram Model
### Part 1: Data Preprocessing 
- Display the top-10 common words and their counts before and after preprocessing.

### Part 2: N-Gram Model and POS Tagging 
- Build a 2-gram model with the processed dataset.
- Show the top-5 probable next words and their probabilities after the initial token.
- Generate a sentence with the 2-gram model and find the corresponding POS taggings.

### Part 3: Evaluation

## Lab 2: Clustering Techniques
### Part 1: K-Means Clustering
- Determine the optimal value of k.

### Part 2: Agglomerative Clustering
- Implement three hierarchical clustering methods.

## Lab 3: Parsing and HMM Implementation
### Part 1: Parsing
- Render dependency trees.
- Implement constituency parsing.
- Perform dependency parsing using Spacy.

### Part 2: HMM Implementation
- Solve the POS tagging task with Hidden Markov Models (HMM) and Viterbi algorithm.

## Lab 4: Text Classification with BERT
- Utilize BERT (Bidirectional Encoder Representations from Transformers) for text classification tasks.
